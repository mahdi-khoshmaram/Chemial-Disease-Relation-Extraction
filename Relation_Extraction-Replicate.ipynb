{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "8cpCwoPOh4oF",
        "outputId": "0cfcedcd-1a99-45c2-e13c-d600d784fee2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting replicate\n",
            "  Downloading replicate-0.26.0-py3-none-any.whl (40 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m40.0/40.0 kB\u001b[0m \u001b[31m481.9 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting httpx<1,>=0.21.0 (from replicate)\n",
            "  Downloading httpx-0.27.0-py3-none-any.whl (75 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m75.6/75.6 kB\u001b[0m \u001b[31m1.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from replicate) (24.0)\n",
            "Requirement already satisfied: pydantic>1.10.7 in /usr/local/lib/python3.10/dist-packages (from replicate) (2.7.3)\n",
            "Requirement already satisfied: typing-extensions>=4.5.0 in /usr/local/lib/python3.10/dist-packages (from replicate) (4.12.1)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.21.0->replicate) (3.7.1)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.21.0->replicate) (2024.6.2)\n",
            "Collecting httpcore==1.* (from httpx<1,>=0.21.0->replicate)\n",
            "  Downloading httpcore-1.0.5-py3-none-any.whl (77 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m77.9/77.9 kB\u001b[0m \u001b[31m1.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: idna in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.21.0->replicate) (3.7)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.21.0->replicate) (1.3.1)\n",
            "Collecting h11<0.15,>=0.13 (from httpcore==1.*->httpx<1,>=0.21.0->replicate)\n",
            "  Downloading h11-0.14.0-py3-none-any.whl (58 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m4.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic>1.10.7->replicate) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.18.4 in /usr/local/lib/python3.10/dist-packages (from pydantic>1.10.7->replicate) (2.18.4)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio->httpx<1,>=0.21.0->replicate) (1.2.1)\n",
            "Installing collected packages: h11, httpcore, httpx, replicate\n",
            "Successfully installed h11-0.14.0 httpcore-1.0.5 httpx-0.27.0 replicate-0.26.0\n"
          ]
        }
      ],
      "source": [
        "!pip install replicate"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "l9uFTVZEuWOT"
      },
      "outputs": [],
      "source": [
        "import google.colab.drive as drive\n",
        "import replicate\n",
        "import json\n",
        "import re\n",
        "import os"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wbHf_Qaz14Xt"
      },
      "outputs": [],
      "source": [
        "class Dataset:\n",
        "    def __init__(self, from_drive=True):\n",
        "        self.dictionaryofdocs = {}\n",
        "        self.from_drive = from_drive\n",
        "        # google drive\n",
        "        print(f\"from_drive: {from_drive}\")\n",
        "        if from_drive == True:\n",
        "            drive.mount('/content/drive')\n",
        "            print(\"---------------Connected to your drive---------------\")\n",
        "\n",
        "    def load(self, url):\n",
        "        # -----------------------------------------\n",
        "        with open(url, \"r\") as fh:\n",
        "            self.pubtaturtext = fh.read()\n",
        "        # -----------------------------------------\n",
        "        # parse data and make list of records\n",
        "        pattern = \"\\n\\n\"\n",
        "        self.listofdocs = re.split(pattern, self.pubtaturtext)\n",
        "        # -----------------------------------------\n",
        "        for doc in self.listofdocs:\n",
        "            if doc.strip() == '':\n",
        "                self.listofdocs.remove(doc)\n",
        "        # -----------------------------------------\n",
        "        for doc in self.listofdocs:\n",
        "            doc = doc.strip()\n",
        "            # [id, record]\n",
        "            id_record = doc.split('|t|')\n",
        "            # id [id, -]\n",
        "            doc_id = id_record[0].strip()\n",
        "            # create key:val = doc_id:{}\n",
        "            self.dictionaryofdocs[doc_id] = {}\n",
        "            # record[-, record]\n",
        "            record =  id_record[1]\n",
        "            # record = [titel, rels]\n",
        "            title_rel = record.split(doc_id)\n",
        "            # title [title, -]\n",
        "            title = title_rel[0].strip()\n",
        "            # create key:val = doc_id:{title:{title}}\n",
        "            self.dictionaryofdocs[doc_id][\"title\"] = title\n",
        "            # append each rel of a record to rels list\n",
        "            self.dictionaryofdocs[doc_id][\"rels\"] = []\n",
        "            for rel in title_rel[1:]:\n",
        "                rel = rel.strip().split('\\t')\n",
        "                relation = rel[0]\n",
        "                chemical = rel[1]\n",
        "                disease = rel[2]\n",
        "                self.dictionaryofdocs[doc_id][\"rels\"].append({\n",
        "                    \"relation\":relation,\n",
        "                    \"chemical\": chemical,\n",
        "                    \"disease\":disease\n",
        "                })\n",
        "        # -----------------------------------------\n",
        "        return self.dictionaryofdocs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6JxC0l6S9gDn"
      },
      "outputs": [],
      "source": [
        "class Makeprompt:\n",
        "    def __init__(self, dictofdocuments):\n",
        "        self.dictofdocuments = dictofdocuments\n",
        "\n",
        "    def prompt(self, doc_id):\n",
        "        self.doc_id = doc_id\n",
        "        self.title_as_prompt = self.dictofdocuments[self.doc_id][\"title\"]\n",
        "        return self.title_as_prompt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NBauZzfXskSN"
      },
      "outputs": [],
      "source": [
        "class Llm:\n",
        "    def __init__(self, cloud_token):\n",
        "        self.cloud_token = cloud_token\n",
        "        os.environ[\"REPLICATE_API_TOKEN\"] = cloud_token\n",
        "        print(\"---------------Connected to Replicate---------------\")\n",
        "\n",
        "    def load_params(self, model, prompt_template, system_prompt, top_k=0, top_p=0.9 , max_tokens=512, min_tokens=0, temperature=0.6, length_penalty=1, stop_sequences=\"<|end_of_text|>,<|eot_id|>\", presence_penalty=1.15, log_performance_metrics=False):\n",
        "        self.model = model\n",
        "        self.prompt_template = prompt_template\n",
        "        self.input = {\n",
        "        \"top_k\": top_k,\n",
        "        \"top_p\": top_p,\n",
        "        \"max_tokens\": max_tokens,\n",
        "        \"min_tokens\": min_tokens,\n",
        "        \"temperature\": temperature,\n",
        "        \"system_prompt\": system_prompt,\n",
        "        \"length_penalty\": length_penalty,\n",
        "        \"stop_sequences\": stop_sequences,\n",
        "        \"presence_penalty\": presence_penalty,\n",
        "        \"log_performance_metrics\": log_performance_metrics}\n",
        "\n",
        "    def generate(self, promptt):\n",
        "        self.input[\"prompt\"] = promptt\n",
        "        self.input[\"prompt_template\"] = self.prompt_template[0] + promptt + self.prompt_template[1]\n",
        "\n",
        "        self.output = replicate.run(self.model, input=self.input)\n",
        "        self.output = \"\".join(self.output)\n",
        "        return self.output"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-0pqs86DfL8S"
      },
      "outputs": [],
      "source": [
        "class Pubtatur:\n",
        "    def __init__(self, results_as_dictionary, to_drive=True):\n",
        "        self.results_as_dictionary = results_as_dictionary\n",
        "        self.to_drive = to_drive\n",
        "        # if to_drive:\n",
        "        #     drive.mount('/content/drive')\n",
        "        #     print(\"---------------Connected to your drive---------------\")\n",
        "\n",
        "    # ----------------------------------------------------\n",
        "    def write(self):\n",
        "        for doc_id in self.results_as_dictionary.keys():\n",
        "            # grabs title related to the id from results_as_dictionary\n",
        "            title_as_promptt = self.results_as_dictionary[doc_id][\"prompt\"]\n",
        "\n",
        "            # grabs list of generated rels related to the id from results_as_dictionary\n",
        "            gen_rels = self.results_as_dictionary[doc_id][\"rels\"]\n",
        "\n",
        "            if self.to_drive:\n",
        "                save_path = \"/content/drive/MyDrive/relation extraction/results.pubtatur.text\"\n",
        "            else:\n",
        "                save_path = \"results.pubtatur.text\"\n",
        "\n",
        "            with open(save_path, 'a') as file:\n",
        "                file.write(f\"{doc_id}|t|{title_as_promptt}\")\n",
        "                for rel in gen_rels:\n",
        "                    rel_type = rel[\"relation\"]\n",
        "                    chemi = rel[\"chemical\"]\n",
        "                    disea = rel[\"disease\"]\n",
        "                    file.write(f\"\\n{doc_id}\\t{rel_type}\\t{chemi}\\t{disea}\")\n",
        "                file.write(\"\\n\\n\")\n",
        "\n",
        "        if self.to_drive:\n",
        "            print(f\"\\n\\n---------------file as Pubtatur format saved in Google drive---------------\\n---------------saved path={save_path}---------------\")\n",
        "        else:\n",
        "            print(f\"---------------file as Pubtatur format saved in current directory---------------\")\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "r0Ej29Y2KJzy"
      },
      "outputs": [],
      "source": [
        "class log:\n",
        "    def __init__(self, documentid, title_prompt, list_of_dict_of_rels):\n",
        "        with open(\"log.txt\", \"a\") as logfile:\n",
        "            logfile.write(f\"id: {documentid}\")\n",
        "            logfile.write(f\"\\nprompt: {title_prompt}\")\n",
        "            logfile.write(f\"\\nlist_of_dict_of_rels: {list_of_dict_of_rels}\")\n",
        "            logfile.write('\\n\\n')\n",
        "        with open(\"/content/drive/MyDrive/relation extraction/log.txt\", \"a\") as logfile:\n",
        "            logfile.write(f\"id: {documentid}\")\n",
        "            logfile.write(f\"\\nprompt: {title_prompt}\")\n",
        "            logfile.write(f\"\\nlist_of_dict_of_rels: {list_of_dict_of_rels}\")\n",
        "            logfile.write('\\n\\n')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Bxf3hTiNj_3f"
      },
      "outputs": [],
      "source": [
        "prompt_template_leftside = f\"\"\"\n",
        "<|begin_of_text|>\n",
        "<|start_header_id|>system<|end_header_id|>\n",
        "\\n\\nYou are a knowledgeable physician. You are tasked with extracting chemical-disease relations from medical texts. CID stands for Chemical-induced-disease relationship. Given a medical text, extract relevant relations and present them in a structured format. each relation is expressed as 'CID***chemical***disease'. remember extract at least one relation. Some examples are provided below:\n",
        "\n",
        "Example 1:\n",
        "Text: \"Electrocardiographic evidence of myocardial injury in psychiatrically hospitalizedcocaine abusers.The electrocardiograms (ECG) of 99 cocaine-abusing patients were compared with theECGs of 50 schizophrenic controls. Eleven of the cocaine abusers and none of thecontrols had ECG evidence of significant myocardial injury defined as myocardialinfarction, ischemia, and bundle branch block.\"\n",
        "Relation(s):\n",
        "CID***cocaine***myocardial infarction\n",
        "CID***cocaine***bundle branch block\n",
        "\n",
        "Example 2:\n",
        "Text: \"Lidocaine-induced cardiac asystole.Intravenous administration of a single 50-mg bolus of lidocaine in a 67-year-oldman resulted in profound depression of the activity of the sinoatrial andatrioventricular nodal pacemakers. The patient had no apparent associated conditionswhich might have predisposed him to the development of bradyarrhythmias; and, thus,this probably represented a true idiosyncrasy to lidocaine.\"\n",
        "Relation(s):\n",
        "CID***Lidocaine***cardiac asystole\n",
        "\n",
        "<|eot_id|>\n",
        "\n",
        "<|start_header_id|>user<|end_header_id|>\n",
        "\\n\\nText: \"\"\"\n",
        "\n",
        "prompt_template_rightside = \"\"\"\n",
        "<|eot_id|>\n",
        "\n",
        "<|start_header_id|>assistant<|end_header_id|>\n",
        "\\n\\nRelation(s):\\n\n",
        "\"\"\"\n",
        "prompt_template = [prompt_template_leftside, prompt_template_rightside]\n",
        "\n",
        "system_prompt = \"\"\"\n",
        "You are a knowledgeable physician. You are tasked with extracting chemical-disease relations from medical texts. CID stands for Chemical-induced-disease relationship. Given a medical text, extract relevant relations and present them in a structured format. each relation is expressed as 'CID***chemical***disease'. remember extract at least one relation. Some examples are provided below:\n",
        "\n",
        "Example 1:\n",
        "Text: \"Electrocardiographic evidence of myocardial injury in psychiatrically hospitalizedcocaine abusers.The electrocardiograms (ECG) of 99 cocaine-abusing patients were compared with theECGs of 50 schizophrenic controls. Eleven of the cocaine abusers and none of thecontrols had ECG evidence of significant myocardial injury defined as myocardialinfarction, ischemia, and bundle branch block.\"\n",
        "Relation(s):\n",
        "CID***cocaine***myocardial infarction\n",
        "CID***cocaine***bundle branch block\n",
        "\n",
        "Example 2:\n",
        "Text: \"Lidocaine-induced cardiac asystole.Intravenous administration of a single 50-mg bolus of lidocaine in a 67-year-oldman resulted in profound depression of the activity of the sinoatrial andatrioventricular nodal pacemakers. The patient had no apparent associated conditionswhich might have predisposed him to the development of bradyarrhythmias; and, thus,this probably represented a true idiosyncrasy to lidocaine.\"\n",
        "Relation(s):\n",
        "CID***Lidocaine***cardiac asystole\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zvDbphNITQ-M"
      },
      "outputs": [],
      "source": [
        "class main:\n",
        "    def __init__(self, dataset_url, cloudtoken, modelname, from_drive=True, prompt_template=prompt_template, system_prompt=system_prompt):\n",
        "        fromdrive = Dataset(from_drive)\n",
        "        docs_as_dict = fromdrive.load(dataset_url)\n",
        "        chat = Llm(cloud_token=cloudtoken)\n",
        "        chat.load_params(model=modelname, prompt_template=prompt_template, system_prompt=system_prompt)\n",
        "\n",
        "        # init Makeprompt object\n",
        "        make = Makeprompt(docs_as_dict)\n",
        "        # creating dictionary to put results in it\n",
        "        results_as_dict = {}\n",
        "        # creating prompts one by one and pass it to LLM\n",
        "        passed_docs = 0\n",
        "        for docid in list(docs_as_dict.keys())[490:500]:\n",
        "            # set prompt related to id\n",
        "            my_prompt = make.prompt(docid)\n",
        "            # pass prompt to llm and get output as list of relations\n",
        "            llm_output = chat.generate(my_prompt).split('\\n')\n",
        "            # print(llm_output)\n",
        "            # break\n",
        "            # make a dictionary of results\n",
        "            results_as_dict[docid] = {}\n",
        "            results_as_dict[docid][\"prompt\"] = my_prompt\n",
        "            results_as_dict[docid][\"rels\"] = []\n",
        "            for relation in llm_output:\n",
        "                splitted_relation = relation.split(\"***\")\n",
        "                rel = splitted_relation[0]\n",
        "                chem = splitted_relation[1]\n",
        "                dis = splitted_relation[2]\n",
        "                results_as_dict[docid][\"rels\"].append({\n",
        "                    \"relation\":rel,\n",
        "                    \"chemical\":chem,\n",
        "                    \"disease\":dis\n",
        "                })\n",
        "            print(f\"{passed_docs}, {docid}\")\n",
        "            # log\n",
        "            log(documentid=docid, title_prompt=results_as_dict[docid][\"prompt\"], list_of_dict_of_rels=results_as_dict[docid][\"rels\"])\n",
        "            passed_docs += 1\n",
        "        make_pub = Pubtatur(results_as_dict)\n",
        "        make_pub.write()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "o0yX9vo0H8-i"
      },
      "outputs": [],
      "source": [
        "dataset_url = \"/content/drive/MyDrive/relation extraction/test.PubTator_edited.txt\"\n",
        "token = \"Replicate Token\"\n",
        "model = \"meta/meta-llama-3-70b-instruct\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "eBc3e6mvFgLo",
        "outputId": "1ffd2543-aa1c-4f68-8218-4f78aa729915"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "from_drive: True\n",
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "---------------Connected to your drive---------------\n",
            "---------------Connected to Replicate---------------\n",
            "['CID***fluvastatin***liver damage', 'CID***fluvastatin***acute liver injury', 'CID***fluvastatin***hepatic damage']\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<__main__.main at 0x7ed630548820>"
            ]
          },
          "execution_count": 24,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "main(dataset_url=dataset_url, cloudtoken=token, modelname=model)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
